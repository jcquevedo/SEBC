
<code><b>HADOOP_USER_NAME=saturn time hadoop jar /opt/cloudera/parcels/CDH/lib/hadoop-0.20-mapreduce/hadoop-examples.jar teragen 65536000 /user/saturn/tgen</b></code><br>

17/12/01 14:23:34 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id<br>
17/12/01 14:23:34 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=<br>
17/12/01 14:23:34 INFO terasort.TeraSort: Generating 65536000 using 1<br>
17/12/01 14:23:34 INFO mapreduce.JobSubmitter: number of splits:1<br>
17/12/01 14:23:34 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1424968212_0001<br>
17/12/01 14:23:34 INFO mapreduce.Job: The url to track the job: http://localhost:8080/<br>
17/12/01 14:23:34 INFO mapreduce.Job: Running job: job_local1424968212_0001<br>
17/12/01 14:23:34 INFO mapred.LocalJobRunner: OutputCommitter set in config null<br>
17/12/01 14:23:34 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1<br>
17/12/01 14:23:34 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter<br>
17/12/01 14:23:34 INFO mapred.LocalJobRunner: Waiting for map tasks<br>
17/12/01 14:23:34 INFO mapred.LocalJobRunner: Starting task: attempt_local1424968212_0001_m_000000_0<br>
17/12/01 14:23:34 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1<br>
17/12/01 14:23:34 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]<br>
17/12/01 14:23:34 INFO mapred.MapTask: Processing split: <br>org.apache.hadoop.examples.terasort.TeraGen$RangeInputFormat$RangeInputSplit@407773d4<br>
17/12/01 14:23:35 INFO mapreduce.Job: Job job_local1424968212_0001 running in uber mode : false<br>
17/12/01 14:23:35 INFO mapreduce.Job:  map 0% reduce 0%<br>
17/12/01 14:23:40 INFO mapred.LocalJobRunner: map > map<br>
17/12/01 14:23:41 INFO mapreduce.Job:  map 8% reduce 0%<br>
17/12/01 14:23:43 INFO mapred.LocalJobRunner: map > map<br>
17/12/01 14:23:44 INFO mapreduce.Job:  map 13% reduce 0%<br>
17/12/01 14:23:46 INFO mapred.LocalJobRunner: map > map<br>
17/12/01 14:23:47 INFO mapreduce.Job:  map 17% reduce 0%<br>
17/12/01 14:23:49 INFO mapred.LocalJobRunner: map > map<br>
17/12/01 14:23:50 INFO mapreduce.Job:  map 22% reduce 0%<br>
17/12/01 14:23:52 INFO mapred.LocalJobRunner: map > map<br>
17/12/01 14:23:53 INFO mapreduce.Job:  map 26% reduce 0%<br>
17/12/01 14:23:55 INFO mapred.LocalJobRunner: map > map<br>
17/12/01 14:23:56 INFO mapreduce.Job:  map 30% reduce 0%<br>
17/12/01 14:23:58 INFO mapred.LocalJobRunner: map > map<br>
17/12/01 14:23:59 INFO mapreduce.Job:  map 35% reduce 0%<br>
17/12/01 14:24:01 INFO mapred.LocalJobRunner: map > map<br>
17/12/01 14:24:02 INFO mapreduce.Job:  map 39% reduce 0%<br>
17/12/01 14:24:04 INFO mapred.LocalJobRunner: map > map<br>
17/12/01 14:24:05 INFO mapreduce.Job:  map 44% reduce 0%<br>
17/12/01 14:24:07 INFO mapred.LocalJobRunner: map > map<br>
17/12/01 14:24:08 INFO mapreduce.Job:  map 47% reduce 0%<br>
17/12/01 14:24:10 INFO mapred.LocalJobRunner: map > map<br>
17/12/01 14:24:11 INFO mapreduce.Job:  map 51% reduce 0%<br>
17/12/01 14:24:13 INFO mapred.LocalJobRunner: map > map<br>
17/12/01 14:24:14 INFO mapreduce.Job:  map 54% reduce 0%<br>
17/12/01 14:24:16 INFO mapred.LocalJobRunner: map > map<br>
17/12/01 14:24:17 INFO mapreduce.Job:  map 55% reduce 0%<br>
17/12/01 14:24:19 INFO mapred.LocalJobRunner: map > map<br>
17/12/01 14:24:20 INFO mapreduce.Job:  map 57% reduce 0%<br>
17/12/01 14:24:22 INFO mapred.LocalJobRunner: map > map<br>
17/12/01 14:24:23 INFO mapreduce.Job:  map 59% reduce 0%<br>
17/12/01 14:24:25 INFO mapred.LocalJobRunner: map > map<br>
17/12/01 14:24:26 INFO mapreduce.Job:  map 63% reduce 0%<br>
17/12/01 14:24:28 INFO mapred.LocalJobRunner: map > map<br>
17/12/01 14:24:29 INFO mapreduce.Job:  map 65% reduce 0%<br>
17/12/01 14:24:31 INFO mapred.LocalJobRunner: map > map<br>
17/12/01 14:24:32 INFO mapreduce.Job:  map 67% reduce 0%<br>
17/12/01 14:24:34 INFO mapred.LocalJobRunner: map > map<br>
17/12/01 14:24:35 INFO mapreduce.Job:  map 70% reduce 0%<br>
17/12/01 14:24:37 INFO mapred.LocalJobRunner: map > map<br>
17/12/01 14:24:38 INFO mapreduce.Job:  map 72% reduce 0%<br>
17/12/01 14:24:40 INFO mapred.LocalJobRunner: map > map<br>
17/12/01 14:24:41 INFO mapreduce.Job:  map 74% reduce 0%<br>
17/12/01 14:24:43 INFO mapred.LocalJobRunner: map > map<br>
17/12/01 14:24:44 INFO mapreduce.Job:  map 76% reduce 0%<br>
17/12/01 14:24:46 INFO mapred.LocalJobRunner: map > map<br>
17/12/01 14:24:47 INFO mapreduce.Job:  map 78% reduce 0%<br>
17/12/01 14:24:49 INFO mapred.LocalJobRunner: map > map<br>
17/12/01 14:24:50 INFO mapreduce.Job:  map 81% reduce 0%<br>
17/12/01 14:24:52 INFO mapred.LocalJobRunner: map > map<br>
17/12/01 14:24:53 INFO mapreduce.Job:  map 84% reduce 0%<br>
17/12/01 14:24:55 INFO mapred.LocalJobRunner: map > map<br>
17/12/01 14:24:56 INFO mapreduce.Job:  map 86% reduce 0%<br>
17/12/01 14:24:58 INFO mapred.LocalJobRunner: map > map<br>
17/12/01 14:24:59 INFO mapreduce.Job:  map 88% reduce 0%<br>
17/12/01 14:25:01 INFO mapred.LocalJobRunner: map > map<br>
17/12/01 14:25:02 INFO mapreduce.Job:  map 91% reduce 0%<br>
17/12/01 14:25:04 INFO mapred.LocalJobRunner: map > map<br>
17/12/01 14:25:05 INFO mapreduce.Job:  map 93% reduce 0%<br>
17/12/01 14:25:07 INFO mapred.LocalJobRunner: map > map<br>
17/12/01 14:25:08 INFO mapreduce.Job:  map 95% reduce 0%<br>
17/12/01 14:25:10 INFO mapred.LocalJobRunner: map > map<br>
17/12/01 14:25:11 INFO mapreduce.Job:  map 98% reduce 0%<br>
17/12/01 14:25:13 INFO mapred.LocalJobRunner: map > map<br>
17/12/01 14:25:14 INFO mapred.LocalJobRunner: map > map<br>
17/12/01 14:25:14 INFO mapreduce.Job:  map 99% reduce 0%<br>
17/12/01 14:25:15 INFO mapred.Task: Task:attempt_local1424968212_0001_m_000000_0 is done. And is in the process of committing<br>
17/12/01 14:25:15 INFO mapred.LocalJobRunner: map > map<br>
17/12/01 14:25:15 INFO mapred.Task: Task attempt_local1424968212_0001_m_000000_0 is allowed to commit now<br>
17/12/01 14:25:16 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1424968212_0001_m_000000_0' to hdfs://hosts3.northcentralus.cloudapp.azure.com:8020/user/saturn/tgen/_temporary/0/task_local1424968212_0001_m_000000<br>
17/12/01 14:25:16 INFO mapred.LocalJobRunner: map<br>
17/12/01 14:25:16 INFO mapred.Task: Task 'attempt_local1424968212_0001_m_000000_0' done.<br>
17/12/01 14:25:16 INFO mapred.LocalJobRunner: Finishing task: attempt_local1424968212_0001_m_000000_0<br>
17/12/01 14:25:16 INFO mapred.LocalJobRunner: map task executor complete.<br>
17/12/01 14:25:16 INFO mapreduce.Job:  map 100% reduce 0%<br>
17/12/01 14:25:18 INFO mapreduce.Job: Job job_local1424968212_0001 completed successfully<br>
17/12/01 14:25:18 INFO mapreduce.Job: Counters: 21<br>
	File System Counters<br>
		FILE: Number of bytes read=276333<br>
		FILE: Number of bytes written=566913<br>
		FILE: Number of read operations=0<br>
		FILE: Number of large read operations=0<br>
		FILE: Number of write operations=0<br>
		HDFS: Number of bytes read=0<br>
		HDFS: Number of bytes written=6553600000<br>
		HDFS: Number of read operations=4<br>
		HDFS: Number of large read operations=0<br>
		HDFS: Number of write operations=3<br>
	Map-Reduce Framework<br>
		Map input records=65536000<br>
		Map output records=65536000<br>
		Input split bytes=83<br>
		Spilled Records=0<br>
		Failed Shuffles=0<br>
		Merged Map outputs=0<br>
		GC time elapsed (ms)=772<br>
		Total committed heap usage (bytes)=245366784<br>
	org.apache.hadoop.examples.terasort.TeraGen$Counters<br>
		CHECKSUM=140750829423462787<br>
	File Input Format Counters <br>
		Bytes Read=0<br>
	File Output Format Counters <br>
		Bytes Written=6553600000<br>
78.48user 7.68system 1:46.71elapsed 80%CPU (0avgtext+0avgdata 211872maxresident)k<br>
0inputs+3136outputs (0major+99943minor)pagefaults 0swaps<br>


<code><b>[root@host1 CDH5]# hdfs dfs -ls /user/saturn/tgen</b></code><<br>
Found 2 items<br>
-rw-r--r--   3 saturn supergroup          0 2017-12-01 14:25 /user/saturn/tgen/_SUCCESS<br>
-rw-r--r--   3 saturn supergroup 6553600000 2017-12-01 14:25 /user/saturn/tgen/part-m-00000<br>


<code><b>[root@host1 CDH5]# hadoop fsck -blocks /user/saturn</b></code><br>
DEPRECATED: Use of this script to execute hdfs command is deprecated.<br>
Instead use the hdfs command for it.<br>

Connecting to namenode via http://hosts3.northcentralus.cloudapp.azure.com:50070<br>
FSCK started by root (auth:SIMPLE) from /10.0.0.9 for path /user/saturn at Fri Dec 01 14:26:38 EST 2017<br>
..Status: HEALTHY<br>
 Total size:	6553600000 B<br>
 Total dirs:	2<br>
 Total files:	2<br>
 Total symlinks:		0<br>
 Total blocks (validated):	49 (avg. block size 133746938 B)<br>
 Minimally replicated blocks:	49 (100.0 %)<br>
 Over-replicated blocks:	0 (0.0 %)<br>
 Under-replicated blocks:	0 (0.0 %)<br>
 Mis-replicated blocks:		0 (0.0 %)<br>
 Default replication factor:	3<br>
 Average block replication:	3.0<br>
 Corrupt blocks:		0<br>
 Missing replicas:		0 (0.0 %)<br>
 Number of data-nodes:		3<br>
 Number of racks:		1<br>
FSCK ended at Fri Dec 01 14:26:38 EST 2017 in 3 milliseconds<br>


The filesystem under path '/user/saturn' is HEALTHY<br>
[root@host1 CDH5]# <br>
<br>